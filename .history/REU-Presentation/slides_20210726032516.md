---
theme: apple-basic
image: './images/chicago.jpg'
class: text-center
lineNumbers: false
layout: intro-image
info: |
  ## REU Final Presentation
  Made by Matthew Chen
title: Slidev Presentation
fonts:
  weights: '100,200,400'


---

# BigDataX Final Presentation

By: Matthew Chen \
Advised by: Tyler Skluzacek and Kyle Chard


---
theme: apple-basic
layout: image-right
image: "./images/XtractData.PNG"

---

# Introduction

Xtract is a distributed metadata extraction service designed to reduce extraction time and data transfer costs.

* âŒ› + ðŸ’° **Scheduler** - High performance computers --> limited compute time 
  - Given fixed budget extract as much metadata as fast as possible

* ðŸ”ŽðŸ“„ **Survey of File Type Identification Methods** 
  - Clustering (K-means, Hierarchical) + Visualization (PCA, kPCA, T-SNE)
  - ML-Methods (Xtract-Sampler's Logistic Regression, Support Vector Machines, and Random Forests)
  - Deep Learning Methods - Convolutional Neural Networks (In Progress)


---
layout: image-right
image: "./images/combine_images.png"
---

# Motivation + Literature Review
<span font-size=4em>
<ul>
 <li> File type identification is a growing subfield within the field of digital forensics</li>
 <li> "Content Based File Type Detection Algorithms" McDaniel and Heydari (2002) </li>
 <li> Analyzed notably Byte Frequency Distributions and File Header/Trailer's </li>
 <li> State of art paper: Systematic Classification Engine for Advanced Data Analysis (SCEADAN) by Beebe et. al in 2014</li>
 <li> Achieved approximately 75% classification accuracy on over 30 different file types w/ only BFDs and SVMs</li>
</ul>
</span>

---
layout: quote
---

 ## "Although several researchers have been focused on the development of new methods to improve the quality of the data stored in research data repositories ... there is little research on the data quality issues of the metadata used to describe and annotate datasets in this type of repositories. The use of complete and accurate metadata is important for several processes, including the re-use and sharing of research datasets among scientists; the application of digital curation and data provenance strategies; and the analysis of the contents of research data repositories."

- Rousidis and Garoufallou ("Metadata for Big Data: A preliminary investigation of metadata quality issues in research data repositories", 2014)


---
layout: image-right
image: "./images/bfd.PNG" 
---
# Methods - Data
## Byte Frequency Distributions
### 1-grams
- Frequency of bytes (0x00 to 0xFF) per file (256 values)
### 2-grams
- Frequency of pairs of bytes (0x00-0x01 to 0xFF-0xFF) (65336 values)
## Byte Vectors
- Simply the first X amount of bytes from a head i.e. ([234, 18, 0, 16, ...]) 
- Widely used in literature as an accurate metric for identification + Xtract-Sampler


---
layout: image-right
image: "./images/KmeansFail.PNG"

---
# Methods - Clustering
## Feature Reduction
### PCA, kPCA, Feature Agglomeration
- Given the number of dimensions clustering is required for visualization
- PCA (Linear) vs. kPCA + Feature Agglomeration (Non-Linear)
## Clustering
### K-Means and Hierarchical Clustering
- Popular clustering methods used in an unsupervised setting
- Compared to true labels misidentified them (ineffective)

---
layout: image-right
image: "./images/TSNEBadReal.PNG"
---

# Methods - Visualization 

- When all other methods failed T-Distributed Stochastic Neighborhood Embedding (T-SNE) proved useful
  - Mainly used for visualizing higher dimensional data
  - Non-Linear method
  - Approximates distances via probabilities of how close two points should be to one another


---

# Methods - Xtract Sampler

- Within Xtract's service the sampler implements various machine learning methods in `sklearn` including Support Vector Machines (SVMs), Logistic Regression, and Random Forests (RFs) to predict the best extractor for the file
  - Use byte vectors (Typically 512 bytes from the head) to predict file
  - High Accuracy at around 70% to 95% accuracy 

```ts {1|2|all}
    prediction = trained_classifier.predict(x)
    prediction_probabilities = probability_dictionary(trained_classifier.predict_proba(x)[0], label_map)
```
  - Precision, Recall, and ROC (Reciever Operating Characteristic) Curves demonstrate effective classification with few false positives/negatives  
  
- Exhaustive search of classifier's hyperparameters to find best accuracy, precision, and recall

---
layout: two-cols
---

<template v-slot:default>

# Methods - Xtract Scheduler

- Given a constrained computational budget the scheduler attempts to maximize the amount of metadata extract in the least amount of time
- For testing and experimentation the Carbon Dioxide Information Analysis Center (CDIAC) Pub8 is used 
- Propose a metric for maximizing amount of metadata per second
- Simulate effectiveness
  - Extracted metadata already known before scheduler

</template>
<template v-slot:right>

## Objective Function: 

$$ \alpha(F) = S(F) \circ P(F) \circ \frac{1}{T(F)} $$

- where $\circ$ represents the Hadamard Product (pairwise multiplication), $S$ represents the vector of predicted sizes of metadata files, $P$ represents a vector of probabilities for how effective each extractor will work on the file, and $T$ represents the vector of estimated times for a file
- the function takes in a file and outputs a vector of length equal to the number of extractors available + 1 for the unknown extractor
- *Conceptually the objective function calculates expected amount of metadata per second*

</template>

---
---

# Methods - Xtract Scheduler (cont.)

- Various regression techniques from `sklearn` were used to estimate the expected size of metadata generated and time taken from extraction using data from extracting CDIAC's Pub8
```ts {all|1|6|all}
pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))
pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))
pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))
pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))
pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))
pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))

for name, model in pipelines:
    kfold = KFold(n_splits=10, random_state=42, shuffle=True)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')
```
- For some xtractors data was log-scaled to provide better fits/less loss 

- Linear Regression and Gradient Boosted Regression worked best


---
---
# Methods - Xtract Scheduler (cont.)


### Workflow:

```mermaid

graph LR;
A[Train Xtract Sampler <br> Classification Models]
B[Train Regression Models <br> to estimate size and time]
C[Calculate objective function <br> for each file in directory]
D[Insert file into a queue implemented as a <br> heap sorted by objective function value]
E[Pop from queue highest values]
F[Extract from each file popped off the queue]

A-->B; 
C-->D;
E-->F;

```

### Note:
For the last step, multiple worker processes are generated for faster extraction



---
layout: image-right
image: "./images/ByteHeadSize.PNG"
---

# Experimentation

- In each of these methods 6 extractors were used:
  - Image
  - Tabular
  - Keyword
  - NetCDF
  - JSON/XML
  - "Unknown"

- For clustering variable sizes of byte heads were extracted:
  - 256B, 512B, 1024B, 256KB, 512KB, 1MB
- For the sampler only 512 bytes from the head were used

---

# Results - Clustering

- T-SNE proved to be the only viable method of visualization + attempting to cluster in a 2-3 dimensional space
- PCA and k-PCA could not handle the extreme amount of variance in each of the features
  - Even with 3 dimensions PCA only could have approximately a 60% explained variance ratio
- Byte Vectors proved to be just as effective as Byte Frequency Distributions in True-Label Clustering
  - Size reductions all the way down to 1024 Bytes analyzed did not effect clustering
- K-Means and Agglormerative Clustering failed to identify true clusters
  - Silohouette scores for K-means were 10x than true label scores, but had only around 30-40% accuracy in grouping clusters properly

---

layout: 3-images

---





---
---

# Components

<div grid="~ cols-2 gap-4">
<div>

You can use Vue components directly inside your slides.

We have provided a few built-in components like `<Tweet/>` and `<Youtube/>` that you can use directly. And adding your custom components is also super easy.

```html
<Counter :count="10" />
```

<!-- ./components/Counter.vue -->
<Counter :count="10" m="t-4" />

Check out [the guides](https://sli.dev/builtin/components.html) for more.

</div>
<div>

```html
<Tweet id="1390115482657726468" />
```

<Tweet id="1390115482657726468" scale="0.65" />

</div>
</div>


---
class: px-20
---

# Themes

Slidev comes with powerful theming support. Themes can provide styles, layouts, components, or even configurations for tools. Switching between themes by just **one edit** in your frontmatter:

<div grid="~ cols-2 gap-2" m="-t-2">

```yaml
---
theme: default
---
```

```yaml
---
theme: seriph
---
```

<img border="rounded" src="https://github.com/slidevjs/themes/blob/main/screenshots/theme-default/01.png?raw=true">

<img border="rounded" src="https://github.com/slidevjs/themes/blob/main/screenshots/theme-seriph/01.png?raw=true">

</div>

Read more about [How to use a theme](https://sli.dev/themes/use.html) and
check out the [Awesome Themes Gallery](https://sli.dev/themes/gallery.html).

---
preload: false
---

# Animations

Animations are powered by [@vueuse/motion](https://motion.vueuse.org/).

```html
<div
  v-motion
  :initial="{ x: -80 }"
  :enter="{ x: 0 }">
  Slidev
</div>
```

<div class="w-60 relative mt-6">
  <div class="relative w-40 h-40">
    <img
      v-motion
      :initial="{ x: 800, y: -100, scale: 1.5, rotate: -50 }"
      :enter="final"
      class="absolute top-0 left-0 right-0 bottom-0"
      src="https://sli.dev/logo-square.png"
    />
    <img
      v-motion
      :initial="{ y: 500, x: -100, scale: 2 }"
      :enter="final"
      class="absolute top-0 left-0 right-0 bottom-0"
      src="https://sli.dev/logo-circle.png"
    />
    <img
      v-motion
      :initial="{ x: 600, y: 400, scale: 2, rotate: 100 }"
      :enter="final"
      class="absolute top-0 left-0 right-0 bottom-0"
      src="https://sli.dev/logo-triangle.png"
    />
  </div>

  <div 
    class="text-5xl absolute top-14 left-40 text-[#2B90B6] -z-1"
    v-motion
    :initial="{ x: -80, opacity: 0}"
    :enter="{ x: 0, opacity: 1, transition: { delay: 2000, duration: 1000 } }">
    Slidev
  </div>
</div>

<!-- vue script setup scripts can be directly used in markdown, and will only affects current page -->
<script setup lang="ts">
const final = {
  x: 0,
  y: 0,
  rotate: 0,
  scale: 1,
  transition: {
    type: 'spring',
    damping: 10,
    stiffness: 20,
    mass: 2
  }
}
</script>

<div
  v-motion
  :initial="{ x:35, y: 40, opacity: 0}"
  :enter="{ y: 0, opacity: 1, transition: { delay: 3500 } }">

[Learn More](https://sli.dev/guide/animations.html#motion)

</div>

---

# LaTeX

LaTeX is supported out-of-box powered by [KaTeX](https://katex.org/).

<br>

Inline $\sqrt{3x-1}+(1+x)^2$

Block
$$
\begin{array}{c}

\nabla \times \vec{\mathbf{B}} -\, \frac1c\, \frac{\partial\vec{\mathbf{E}}}{\partial t} &
= \frac{4\pi}{c}\vec{\mathbf{j}}    \nabla \cdot \vec{\mathbf{E}} & = 4 \pi \rho \\

\nabla \times \vec{\mathbf{E}}\, +\, \frac1c\, \frac{\partial\vec{\mathbf{B}}}{\partial t} & = \vec{\mathbf{0}} \\

\nabla \cdot \vec{\mathbf{B}} & = 0

\end{array}
$$

<br>

[Learn more](https://sli.dev/guide/syntax#latex)

---

# Diagrams

You can create diagrams / graphs from textual descriptions, directly in your Markdown.

<div class="grid grid-cols-2 gap-10 pt-4 -mb-6">

```mermaid {scale: 0.9}
sequenceDiagram
    Alice->John: Hello John, how are you?
    Note over Alice,John: A typical interaction
```

```mermaid {theme: 'neutral', scale: 0.8}
graph TD
B[Text] --> C{Decision}
C -->|One| D[Result 1]
C -->|Two| E[Result 2]
```

</div>

[Learn More](https://sli.dev/guide/syntax.html#diagrams)


---
layout: center
class: text-center
---

# Learn More

[Documentations](https://sli.dev) Â· [GitHub](https://github.com/slidevjs/slidev) Â· [Showcases](https://sli.dev/showcases.html)
